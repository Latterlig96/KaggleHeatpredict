{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of properties dataframe is : 616.9464874267578  MB\n",
      "******************************\n",
      "Column:  building_id\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  1448\n",
      "dtype after:  uint16\n",
      "******************************\n",
      "******************************\n",
      "Column:  meter\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  3\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  meter_reading\n",
      "dtype before:  float64\n",
      "min for this col:  0.0\n",
      "max for this col:  21904700.0\n",
      "dtype after:  float32\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  289.1937065124512  MB\n",
      "This is  46.875006569639226 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "from DataLoader import train_df,test_df\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from model_utils import trim_site,filling_nan_values\n",
    "from model_utils import percentile_condition\n",
    "from lightworklow import GBM\n",
    "\n",
    "train = train_df(build_meta_csv='./heat_data/building_metadata.csv',\n",
    "                train_csv='./heat_data/train.csv',\n",
    "                weather_train_csv='./heat_data/weather_train.csv',\n",
    "                merge=True,\n",
    "                unmerged=False,\n",
    "                drop=True,\n",
    "                col_drop = ['year_built','timestamp','floor_count'],\n",
    "                axis = 1,\n",
    "                datetime=True,\n",
    "                encode_and_scale=True,\n",
    "                trim_bad_rows = True, \n",
    "                fill_weather = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing outliers based on percentile conditioning\n",
      "Input data shape: (20216100, 18)\n",
      "False/True values while removing the outliers:\n",
      "\n",
      "True     20153452\n",
      "False       62648\n",
      "Name: meter_reading, dtype: int64\n",
      "Final shape after removing outliers: 20216100\n"
     ]
    }
   ],
   "source": [
    "train = percentile_condition(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Column:air_temperature\n",
      "Filling Column:cloud_coverage\n",
      "Filling Column:dew_temperature\n",
      "Filling Column:precip_depth_1_hr\n",
      "Filling Column:sea_level_pressure\n",
      "Filling Column:wind_direction\n",
      "Filling Column:wind_speed\n"
     ]
    }
   ],
   "source": [
    "train = filling_nan_values(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train['meter_reading']\n",
    "train = train.drop(['meter_reading'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of properties dataframe is : 30.517654418945312  MB\n",
      "******************************\n",
      "Column:  row_id\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  999999\n",
      "dtype after:  uint32\n",
      "******************************\n",
      "******************************\n",
      "Column:  building_id\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  104\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "******************************\n",
      "Column:  meter\n",
      "dtype before:  int64\n",
      "min for this col:  0\n",
      "max for this col:  1\n",
      "dtype after:  uint8\n",
      "******************************\n",
      "___MEMORY USAGE AFTER COMPLETION:___\n",
      "Memory usage is:  13.351516723632812  MB\n",
      "This is  43.75014062464844 % of the initial size\n"
     ]
    }
   ],
   "source": [
    "test = test_df(test_csv='./heat_data/test.csv',\n",
    "              weather_test_csv='./heat_data/weather_test.csv',\n",
    "              merge=True,\n",
    "              unmerged=False,\n",
    "              drop=True,\n",
    "              col_drop = ['row_id','timestamp'],\n",
    "              axis = 1,\n",
    "              datetime=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling Column:air_temperature\n",
      "Filling Column:cloud_coverage\n",
      "Filling Column:dew_temperature\n",
      "Filling Column:precip_depth_1_hr\n",
      "Filling Column:sea_level_pressure\n",
      "Filling Column:wind_direction\n",
      "Filling Column:wind_speed\n"
     ]
    }
   ],
   "source": [
    "test = filling_nan_values(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_shape (20153452, 17)\n",
      "X_test_shape (15906217, 15)\n",
      "vaild_predict 20153452\n",
      "test_predictions 15906217\n",
      "Train LightGBM\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[10]\ttraining's rmse: 2.07197\tvalid_1's rmse: 2.23381\n",
      "[20]\ttraining's rmse: 2.0704\tvalid_1's rmse: 2.23221\n",
      "[30]\ttraining's rmse: 2.06897\tvalid_1's rmse: 2.23091\n",
      "[40]\ttraining's rmse: 2.06766\tvalid_1's rmse: 2.22975\n",
      "[50]\ttraining's rmse: 2.06646\tvalid_1's rmse: 2.22888\n",
      "[60]\ttraining's rmse: 2.06534\tvalid_1's rmse: 2.22818\n",
      "[70]\ttraining's rmse: 2.06438\tvalid_1's rmse: 2.22755\n",
      "[80]\ttraining's rmse: 2.06357\tvalid_1's rmse: 2.22694\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c5e7bc8a974d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m                                                      \u001b[0mn_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                                                      \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                                                      categorical_features = None)\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\Kaggle\\KaggleHeatpredict\\scripts\\lightworklow.py\u001b[0m in \u001b[0;36mfold_run\u001b[1;34m(self, src_dir, X_train, y_train, X_test, n_folds, parameters, categorical_features)\u001b[0m\n\u001b[0;32m    192\u001b[0m                                     \u001b[0mevals_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m                                     \u001b[0mverbose_eval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'verbose_eval'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m                                     feval = self.eval_metric)\n\u001b[0m\u001b[0;32m    195\u001b[0m                     \u001b[0mvalid_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_iteration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgbm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_iteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m                     \u001b[0mvalid_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_predictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ma_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    247\u001b[0m                                     evaluation_result_list=None))\n\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 249\u001b[1;33m         \u001b[0mbooster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, train_set, fobj)\u001b[0m\n\u001b[0;32m   1924\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[0;32m   1925\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1926\u001b[1;33m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[0;32m   1927\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mFalse\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1928\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = GBM(train_gbm = True, \n",
    "            train_xg = False, \n",
    "            train_cat = False,\n",
    "            train_ng = False,\n",
    "            test_predict = True, \n",
    "            save_model = True,\n",
    "            save_history = True,\n",
    "            seed = 100,\n",
    "            name = 'LightGBM',\n",
    "            importance = True, \n",
    "            stratify = False,\n",
    "            eval_metric = None, \n",
    "            time_series = False,\n",
    "            prepare_submission = False,\n",
    "            jsonize = True,\n",
    "            show_metric_results = True)\n",
    "\n",
    "parameters = {'boosting_type':'gbdt',\n",
    "             'objective':'regression',\n",
    "             'metric':'rmse',\n",
    "             'learning_rate':0.01,\n",
    "             'num_leaves':30,\n",
    "             'subsample':0.4,\n",
    "             'reg_alpha':0.5,\n",
    "             'reg_lambda':0.5,\n",
    "             'verbose_eval':10,\n",
    "             'early_stopping_rounds':200,\n",
    "             'num_boost_round':300}\n",
    "\n",
    "valid_predictions,test_predictions = models.fold_run(src_dir='LightGBM',\n",
    "                                                     X_train = train, \n",
    "                                                     y_train = labels,\n",
    "                                                     X_test = test,\n",
    "                                                     n_folds = 3,\n",
    "                                                     parameters = parameters,\n",
    "                                                     categorical_features = None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
